# emotion recognition in real time

## Структура репозитория
- emotion_recognition_model.ipynb - сверточная сеть для классификации.
- frontal_camera.ipynb - работа с фронтальной камерой ноутбука, инференс модели.
- resnet_34_7e.pth - веса предобученной модели.
- haarcascade_frontalface_default.xml - детектор лиц, нужен для работы с фронтальной камерой.
- ссылки на [обучающий](https://drive.google.com/file/d/1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16/view?usp=sharing) и [тестовый](https://drive.google.com/file/d/12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K/view?usp=sharing) датасеты

## Постановка задачи
Перед премьерой фильмов/сериалов аудитории обычно показывают трейлеры - короткие ролики, состоящие из наиболее зрелищных моментов. Для составления трейлеров некоторой контрольной группе показывают фильм, а эксперты в это время анализируют их эмоции, тем самым получая возможность найти нужные для трейлера моменты. Однако обрабатывать результаты вручную неэффективно.  
Требуется:
- разработать нейросеть для классификации эмоций
- разработать инструмент для инференса сети с использованием камеры устройства в реальном времени.

## Данные
Архив с фотографиями лиц и метками эмоций. Всего 9 эмоций:
| Эмоция | neutral | anger | contempt | disgust | fear | happy | sad | surprise | uncertain |
| :---:   | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| # семплов | 6795 | 7023 | 3085 | 3155 | 5044 | 5955 | 6740 | 6323 | 5927 |

## Решение (дописать)
### Сверточная нейросеть
За основу была взята сеть ResNet-34 [1] с предобученными весами. Архитектура ResNet хорошо зарекомендовала себя в задачах классификации изображений. Для файнтюнинга было добавлено несколько полносвязных слоев в конец сети.  
Параметры обучения
### Работа в реальном времени
Детектро лиц + фронтальная камера, работает только на локале.

## Результаты
Время обучения и инференса, метрики

## Инструкция по запуску
Запуск файла emotion_recognition_model ведет к обучению модели с нуля, на GPU 1 эпоха занимает ~ 6 минут. 
Для инфренса нужно вызвать метод predict у модели класса $EmotionRecognitionModel$.

## Ссылки
[1] https://arxiv.org/abs/1512.03385
